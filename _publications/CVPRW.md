---
title: "DETR-Based Layered Clothing Segmentation and Fine-Grained Attribute Recognition"
collection: publications
permalink: /publication/CVPRW
date: 2023-06-18
venue: 'IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops'
paperurl: '[https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10219890](https://openaccess.thecvf.com/content/CVPR2023W/CVFAD/papers/Tian_DETR-Based_Layered_Clothing_Segmentation_and_Fine-Grained_Attribute_Recognition_CVPRW_2023_paper.pdf)'
---
Clothing segmentation and fine-grained attribute recognition are challenging tasks at the crossing of computer vision and fashion, which segment the entire ensemble clothing instances as well as recognize detailed attributes of the clothing products from any input human images. Many new models have been developed for the tasks in recent years, nevertheless the segmentation accuracy is less than satisfactory in case of layered clothing or fashion products in different scales. In this paper, a new DEtection TRansformer (DETR) based method is proposed to segment and recognize fine-grained attributes of ensemble clothing instances with high accuracy. In this model, we propose a multi-layered attention module by aggregating features of different scales, determining the various scale components of a single instance, and merging them together. We train our model on the Fashionpedia dataset and demonstrate our method surpasses SOTA models in tasks of layered clothing segmentation and fine-grained attribute recognition.

paperurl: '[https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10219890](https://openaccess.thecvf.com/content/CVPR2023W/CVFAD/papers/Tian_DETR-Based_Layered_Clothing_Segmentation_and_Fine-Grained_Attribute_Recognition_CVPRW_2023_paper.pdf)'

Recommended citation:

@inproceedings{tian2023detr,
  title={DETR-based Layered Clothing Segmentation and Fine-Grained Attribute Recognition},
  author={Tian, Hao and Cao, Yu and Mok, PY},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3534--3538},
  year={2023}
}
